{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "# Setting up the dataset",
   "id": "2c368060cf422d58"
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "initial_id",
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "\n",
    "dataset = load_dataset('detection-datasets/fashionpedia')\n",
    "dataset"
   ]
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "import torch\n",
    "from torchvision import transforms\n",
    "\n",
    "def collate_fn(batch):\n",
    "    images = [item[\"pixel_values\"] for item in batch]\n",
    "    targets = [item[\"objects\"] for item in batch]\n",
    "\n",
    "    # Stack images into a single 4D tensor [B, C, H, W]\n",
    "    # Note: This only works if all images are the same size!\n",
    "    images = torch.stack(images)\n",
    "    return images, targets\n",
    "\n",
    "def transform_fn(examples):\n",
    "    # Basic transforms: Convert PIL to Tensor\n",
    "    # You might want to add Resize() or Normalize() here\n",
    "    t = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "    ])\n",
    "\n",
    "    examples[\"pixel_values\"] = [t(img.convert(\"RGB\")) for img in examples[\"image\"]]\n",
    "    # Keep the objects as they are for the collate_fn to handle\n",
    "    return examples\n",
    "\n",
    "# Apply the transformation to the dataset\n",
    "transformed_dataset = dataset[\"train\"].with_transform(transform_fn)\n",
    "\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "train_dataloader = DataLoader(\n",
    "    transformed_dataset,\n",
    "    batch_size=32,\n",
    "    shuffle=True,\n",
    "    collate_fn=collate_fn\n",
    ")\n",
    "\n",
    "# Test a single batch\n",
    "batch = next(iter(train_dataloader))\n",
    "images, targets = batch\n",
    "print(f\"Batch images shape: {images.shape}\")\n",
    "print(f\"Number of target dicts: {len(targets)}\")"
   ],
   "id": "c7fb49ec84a85c42"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
